{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Learning Basics","metadata":{}},{"cell_type":"markdown","source":"Developed for Jupyter Hub by Hunter Tiner","metadata":{}},{"cell_type":"markdown","source":"## Objectives\n\n- Build binary classification models that predict activity/inactivity of small molecules against human aromatase using supervised learning methods.\n- Evaluate the performance of the developed models using performance measures.","metadata":{}},{"cell_type":"markdown","source":"## 1. Import bioactivity data from PubChem","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we will develop a prediction model for small molecule's activity against human aromatase (https://pubchem.ncbi.nlm.nih.gov/protein/EAW77416), which is encoded by the CYP19A1 gene (https://pubchem.ncbi.nlm.nih.gov/gene/1588). The model will predict the activity of a molecule based on the structure of the molecule (represented with molecular fingerprints).\n\nFor model development, we will use the Tox21 bioassay data for human aromatase, archived in PubChem (https://pubchem.ncbi.nlm.nih.gov/bioassay/743139).  The bioactivity data presented on this page can be downloaded by clicking the \"Download\" button available on this page and then read the data into a data frame.  Alternatively, you can directly load the data into a data frame as shown in the cell below.","metadata":{}},{"cell_type":"code","source":"url <- 'https://pubchem.ncbi.nlm.nih.gov/assay/pcget.cgi?query=download&record_type=datatable&actvty=all&response_type=save&aid=743139'\ndf_raw <- read.csv(url)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(df_raw)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"__Note:__ Lines 0-2 provide the descriptions for each column (data type, descriptions, units, etc).  These rows need be removed.","metadata":{}},{"cell_type":"code","source":"df_raw <- df_raw[3:nrow(df_raw),]\nhead(df_raw)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The column names in this data frame contain white spaces and special characters.  For simplicity, let's rename the columns (no spaces or special characters except for the \"_\" character.)","metadata":{}},{"cell_type":"code","source":"colnames(df_raw)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names <- c('pc_result_tag', 'sid', 'cid', 'activity_outcome', 'activity_score', 'activity_url', 'assay_data_comment', 'activity_summary', 'antagonist_activity', \n          'antagonist_potency', 'antagonist_efficacy', 'viability_activity', 'viability_potency', 'viability_efficacy', 'sample_source')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colnames(df_raw) <- names\ncolnames(df_raw)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Check the number of compounds for each activity group","metadata":{}},{"cell_type":"markdown","source":"First, we need to understand what our data look like.  Especially, we are interested in the activity class of the tested compounds because we are developing a model that classifies small molecules according to their activities against the target.  This information is available in the \"**activity_outcome**\" and \"**activity_summary**\" columns.","metadata":{}},{"cell_type":"code","source":"if(!require(\"dplyr\", quietly=TRUE)) {\n  install.packages(\"httr\", repos=\"https://cloud.r-project.org/\",\n         quiet=TRUE, type=\"binary\")\n  library(\"dplyr\", quietly=TRUE)\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_raw %>% group_by(activity_outcome) %>% tally()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the data in the **activity_outcome** column, there are 379 actives, 7562 inactives, and 2545 inconclusives.","metadata":{}},{"cell_type":"code","source":"df_raw %>% group_by(activity_outcome, activity_summary) %>% tally()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can see that, in the **activity_summary** column, the inconclusive compounds are further classified into subclasses, which include:\n\n- **active agonist**\n- inconclusive\n- inconclusive agonist\n- inconclusive antagonist\n- inconclusive agonist (cytotoxic)\n- inconclusive antagonist (cytotoxic)\n\n","metadata":{}},{"cell_type":"markdown","source":"As implied in the title of this assay record (https://pubchem.ncbi.nlm.nih.gov/bioassay/743139), this assay aims to identify **aromatase inhibitors**.  Therefore, all **active antagonists** (in the activity summary column) were declared to be **active** compounds (in the activity outcome column).\n\nOn the other hand, the assay also identified 612 **active agonists** (in the activity summary column), and they are declared to be **inconclusive** (in the activity outcome column).\n\nWith that said, \"inactive\" compounds in this assay means those which are neither active agonists nor active antagonist.","metadata":{}},{"cell_type":"markdown","source":"It is important to understand that the criteria used for determining whether a compound is active or not in a given assay are selected by the data source who submitted that assay data to PubChem.  For the purpose of this assignment (which aims to develop a binary classifier that tells if a molecule is active or inactive against the target), we should clarify what we mean by \"active\" and \"inactive\".\n\n- **active** : any compounds that can change (either increase or decrease) the activity of the target.  This is equivalent to either **active antagonists** or **active agonists** in the activity summary column.\n- **inactive** : any compounds that do not change the activity of the target.  This is equivalent to **inactive** compounds in the activity summary column.","metadata":{}},{"cell_type":"markdown","source":"## 3. Select active/inactive compounds for model building","metadata":{}},{"cell_type":"markdown","source":"Now we want to select only the active and inactive compounds from the data frame (that is, active agonists, active antagonists, and inactives based on the \"activity summary\" column).","metadata":{}},{"cell_type":"code","source":"df <- df_raw[ which(df_raw$activity_summary=='active agonist' |\n                    df_raw$activity_summary=='active antagonist' |\n                    df_raw$activity_summary=='inactive'), ]\n\nnrow(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(length(unique(df$sid)))\nprint(length(unique(df$cid)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the number of CIDs is not the same as the number of SIDs.  There are two important potential reasons for this observation.  \n\nFirst, not all substances (SIDs) in PubChem have associated compounds (CIDs) because some substances failed during structure standardization.  \\[Remember that, in PubChem, substances are depositor-provided structures and compounds are unique structures extracted from substances through structure standardization.]  Because our model will use structural information of molecules to predict their bioactivity, we need to remove substances without associated CIDs (i.e., no standardized structures).\n\nSecond, some compounds are associated with more than one substances.  In the context of this assay, it means that a compound may be tested multiple times in different samples (which are designated as different substances).  It is not uncommon that different samples of the same chemical may result in conflicting activities (e.g., active agonist in one sample but inactive in another sample).  In this practice, we remove such compounds with conflicting activities.","metadata":{}},{"cell_type":"markdown","source":"## 3-(1) Drop substances without associated CIDs.","metadata":{}},{"cell_type":"markdown","source":"First, check if there are subtances without associated CIDs.","metadata":{}},{"cell_type":"code","source":"sum(is.na(df$cid))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 138 records whose \"cid\" column is NULL, and we want to remove those records.","metadata":{}},{"cell_type":"code","source":"#We are using the complete.cases function which will specify which rows have no missing values. We are specifying the cid column\n\ndf <- df[complete.cases(df$cid), ]\nnrow(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(length(unique(df$sid)))\nprint(length(unique(df$cid)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(is.na(df$cid))   # Check if the NULL values disappeared in the \"cid\" column","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-(2) Remove CIDs with conflicting activities","metadata":{}},{"cell_type":"markdown","source":"Now identify compounds with conflicting activities and remove them.","metadata":{}},{"cell_type":"code","source":"cid_conflict <- data.frame()\nidx_conflict <- data.frame()\n\nfor (mycid in unique(df$cid)){\n    \n    outcomes <- unique(df[df$cid == mycid, 'activity_summary'])\n    \n    if (length(outcomes) > 1){    \n        idx_tmp <- as.data.frame(df[df$cid == mycid,])\n        idx_conflict <- rbind(idx_conflict, idx_tmp)\n        cid_conflict <- rbind(cid_conflict, mycid)\n    }\n}\n\ncat(\"#\" , nrow(cid_conflict) , \"CIDs with conflicting activities [associated with\" , nrow(idx_conflict) , \"rows (SIDs).]\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(idx_conflict,10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using anti_join from the dplyr library!\ndf <- anti_join(df, idx_conflict)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df %>% group_by(activity_summary) %>% tally()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(length(unique(df$sid)))\nprint(length(unique(df$cid)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-(3) Remove redundant data","metadata":{}},{"cell_type":"markdown","source":"The above code cells \\[in 3-(2)] do not remove compounds tested multiple times if the testing results are consistent [e.g., active agonist in all samples (substances)].  The rows corresponding to these compounds are redundant, so we want remove them except for only one row for each compound.","metadata":{}},{"cell_type":"code","source":"df <- df[!duplicated(df$cid),]     # remove duplicate rows except for the first occurring row.\n\nprint(length(unique(df$sid)))\nprint(length(unique(df$cid)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-(4) Adding \"numeric\" activity classes","metadata":{}},{"cell_type":"markdown","source":"In general, the inputs and outputs to machine learning algorithms need to have numerical forms.   \nIn this practice, the input (molecular structure) will be represented with binary fingerprints, which already have numerical forms (0 or 1).  However, the output (activity) is currently in a string format (e.g., 'active agonist', 'active antagonist').  Therefore, we want to add an additional, 'activity' column, which contains numeric codes representing the active and inactive compounds:\n- 1 for actives (either active agonists or active antagonists)\n- 0 for inactives\n\nNote that we are merging the two classes \"active agonist\" and \"active antagonist\", because we are going to build a binary classifer that distinguish actives from inactives.","metadata":{}},{"cell_type":"code","source":"df$activity <- ifelse(df$activity_summary==\"inactive\", 0,1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check if the new column 'activity' is added to (the end of) the data frame.","metadata":{}},{"cell_type":"code","source":"head(df,3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Double-check the count of active/inactive compounds.","metadata":{}},{"cell_type":"code","source":"df %>% group_by(activity_summary) %>% tally()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df %>% group_by(activity) %>% tally()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3-(5) Create a smaller data frame that only contains CIDs and activities.","metadata":{}},{"cell_type":"markdown","source":"Let's create a smaller data frame that only contains CIDs and activities.  This data frame will be merged with a data frame containing molecular fingerprint information.","metadata":{}},{"cell_type":"code","source":"df_activity <- data.frame(df$cid, df$activity)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(df_activity,5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Download structure information for each compound from PubChem","metadata":{}},{"cell_type":"markdown","source":"Now we want to get structure information of the compounds from PubChem (in isomeric SMILES).","metadata":{}},{"cell_type":"code","source":"#cids = df.cid.astype(int).tolist()\ncids <- c(df$cid)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_size <- 200\nnum_cids <- length(cids)\n\nif (num_cids %% chunk_size == 0){\n    num_chunks = num_cids / chunk_size\n} else {\n    num_chunks = num_cids / chunk_size + 1\n    }\n\nnum_chunks <-  round(num_chunks, digits = 0)\n\ncat(\"# CIDs = \", num_cids, \" | \" , \"# CID Chunks = \", num_chunks, \"(chunked by \", chunk_size, \")\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_smiles <- data.frame()\n\nlist_dfs <- c()  # temporary list of data frames\n\nfor (i in 1:(num_chunks-1)){\n    \n    idx1 <- chunk_size * (i - 1) + 1\n    idx2 <- chunk_size * i\n    \n    if ( idx2 > num_cids){\n        idx2 <- num_cids\n    }\n      \n    cidstr <- paste(cids[idx1:pmin(idx2,length(cids))],collapse=\",\")\n    \n    url <- paste('https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/',cidstr,'/property/IsomericSMILES/TXT',sep=\"\")\n   \n    res <- read.csv(url, sep=\",\", header = FALSE )\n    \n    list_dfs <- rbind(list_dfs, res)\n    \n    Sys.sleep(.2)\n                      \n    if ( i %% 5 == 0 ){\n        print(paste(\"Processing Chunk\", i))\n        }\n    }\n\n\ndf_smiles <- cbind(list_dfs, df$cid)\n\nhead(df_smiles)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nrow(df_smiles)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colnames(df_smiles) <- c(\"smiles\",\"cid\")\ndf_smiles <- df_smiles[c(\"cid\", \"smiles\")]\n\nhead(df_smiles, 5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Generate MACCS keys from SMILES.","metadata":{}},{"cell_type":"code","source":"if (!require(\"rcdk\", quietly=TRUE)) {\n install.packages(\"rcdk\", repos=\"https://cloud.r-project.org/\",\n quiet=TRUE, type=\"binary\")\n library(\"rcdk\")\n}\nif (!require(\"fingerprint\", quietly=TRUE)) {\n install.packages(\"fingerprint\", repos=\"https://cloud.r-project.org/\",\n quiet=TRUE, type=\"binary\")\n library(\"fingerprint\")\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_smiles$smiles <- as.character(df_smiles$smiles)\n\nmol <- parse.smiles(df_smiles$smiles)\n\nfp <- lapply(mol, function(x)\n  as.character(get.fingerprint(x, type = 'maccs',\n                               fp.mode = 'bit', verbose=FALSE)))\n             \nfp <- as.matrix(unlist(fp))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(fp)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We split the maccs string into individual columns.","metadata":{}},{"cell_type":"code","source":"maccs <- t(as.data.frame(strsplit(fp, NULL)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We then generate the column names.","metadata":{}},{"cell_type":"code","source":"colnames(maccs) <- paste(\"maccs\", formatC(1:ncol(maccs), width=3, flag=\"0\"), sep = \"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Merge activity data and fingerprint information","metadata":{}},{"cell_type":"code","source":"head(df_activity, 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(maccs, 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data <- df_activity\ndf_data <- cbind(df_data, maccs)\nrownames(df_data) <- NULL","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(df_data, 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In Section 5 of the Python lesson there were two CIDs for which the MACCS keys could not be generated.  They need to be removed from **df_data**.","metadata":{}},{"cell_type":"code","source":"df_data <- subset(df_data, CID!=28145 & CID!=28127)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save df_data in CSV for future use.","metadata":{}},{"cell_type":"code","source":"write.csv(df_data,'df_data.csv',row.names=FALSE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Preparation for model building","metadata":{}},{"cell_type":"markdown","source":"### 7-(1) Loading the data into X and y.","metadata":{}},{"cell_type":"code","source":"head(df_data, 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x <- df_data[,3:ncol(df_data)]\ny <- df_data[\"Activity\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head(x, 3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paste(c(nrow(y), sum(y)))          # Number of actives","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7-(2) Remove zero-variance features","metadata":{}},{"cell_type":"markdown","source":"Some features in X are not helpful in distinguishing actives from inactives, because they are set ON for all compounds or OFF for all compounds.  Such features need to be removed because they would consume more computational resources without improving the model.","metadata":{}},{"cell_type":"code","source":"which(apply(x, 2, var) == 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paste(c(nrow(x), ncol(x)))  #- Before removal","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x <- x[ - as.numeric(which(apply(x, 2, var) == 0))]\n\npaste(c(nrow(x), ncol(x)))  #- After removal","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case, four features had zero variances.  Note that one of them is the first bit (maccs000) of the MACCS keys, which is added as a \"dummy\" to name each of bits 1~166 as maccs001, maccs002, ... maccs166.  ","metadata":{}},{"cell_type":"markdown","source":"### 7-(3) Train-Test-Split (a 9:1 ratio)","metadata":{}},{"cell_type":"markdown","source":"Now split the data set into a training set (90%) and test set (10%).  The training set will be used to train the model.  The developed model will be tested against the test set.","metadata":{}},{"cell_type":"code","source":"if (!require(\"caret\", quietly=TRUE)) {\n  install.packages(\"caret\", repos=\"https://cloud.r-project.org/\",\n                   quiet=TRUE, type=\"binary\")\n  library(\"caret\")\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set.seed(Sys.time())  # using this as a seed will produce different results, this would be more useful in \"real-world\"\nset.seed(3100)\ntest_inds = createDataPartition(y = 1:nrow(y), p = .1, list = F)\n\n# Split data into test/train using indices\nx_test = x[test_inds, ]; y_test = y[test_inds]\nx_train = x[-test_inds, ]; y_train = y[-test_inds]\n\npaste(c(nrow(x_train), ncol(x_train), nrow(x_test), ncol(x_test), length(y_train), length(y_test)))\npaste(c(sum(y_train), sum(y_test)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7-(4) Balance the training set through downsampling","metadata":{}},{"cell_type":"markdown","source":"Check the dimension of the training data set.","metadata":{}},{"cell_type":"code","source":"length(y_train)\nnrow(x_train)\nlength(x_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the number of actives and inactives compound.","metadata":{}},{"cell_type":"code","source":"paste(c(\"# inactives : \", length(y_train) - sum(y_train)))\npaste(c(\"# actives : \", sum(y_train)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data set is highly imbalanced \\[the inactive to active ratio is ~8].  To address this issue, let's downsample the majority class (inactive compounds) to balance the data set.","metadata":{}},{"cell_type":"code","source":"# Indicies of each class' observations\nidx_inactives <- which(sapply(y_train, function(y_train) 0 %in% y_train))\nidx_actives <- which(sapply(y_train, function(y_train) 1 %in% y_train))\n                            \n# Number of observations in each class\nnum_inactives <-  length(idx_inactives)\nnum_actives   <- length(idx_actives)\n\n# Randomly sample from inactives without replacement\n# set.seed(Sys.time())\nset.seed(0)\nidx_inactives_downsampled <- sample(idx_inactives, num_actives, replace = F)\n\n# Join together downsampled inactives with actives\nx_train <- rbind(x_train[idx_inactives_downsampled,], x_train[idx_actives,])\ny_train <- append(y_train[idx_inactives_downsampled], y_train[idx_actives])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is noteworthy that **np.vstack** is used for X_train and **np.hstack** is used for Y_train.  The direction of stacking is different because X_train is a 2-D array and y_train is a 1-D array.\n\nConfirm that the downsampled data set has the correct dimension and active/inactive counts.","metadata":{}},{"cell_type":"code","source":"paste(c(\"# inactives : \", length(y_train) - sum(y_train)))\npaste(c(\"# actives : \", sum(y_train)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length(y_train)\nnrow(x_train)\nlength(x_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Build a model using the training set.","metadata":{}},{"cell_type":"markdown","source":"Now we are ready to build predictive models using machine learning algorithms.  This notebook will use Naive Bayes and decision tree, because they are relatively fast and simple.","metadata":{}},{"cell_type":"code","source":"if (!require(\"e1071\", quietly=TRUE)) {\n  install.packages(\"e1071\", repos=\"https://cloud.r-project.org/\",\n                   quiet=TRUE, type=\"binary\")\n  library(\"e1071\")\n}\nif (!require(\"caTools\", quietly=TRUE)) {\n  install.packages(\"caTools\", repos=\"https://cloud.r-project.org/\",\n                   quiet=TRUE, type=\"binary\")\n  library(\"caTools\")\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#up to this point the R has mimicked our Python lessons.\n#to make things easier, we're gonna mix it up a bit\n# - Hunter T.\n\ny_train <- as.data.frame(y_train)\ny_test <- as.data.frame(y_test)\n\n#rejoin our train and test, the y datasets are our predictors\ntrain <- cbind(y_train, x_train)\ntest <- cbind(y_test, x_test)\n\n#rename the column back to \"activity\"\nnames(train)[1] <- \"activity\"\nnames(test)[1] <- \"activity\"\n\n#since Naive Bayes attempts to classify, we need to make sure that \"activity\"\n#is a factor instead of numeric\ntrain$activity <- as.factor(train$activity)\ntest$activity <- as.factor(test$activity)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8-(1) Naive Bayes","metadata":{}},{"cell_type":"code","source":"#train the model!\nnbModel <- naiveBayes(activity~., data = train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use the model to predict\nnbPredict <- predict(nbModel, test[,-1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table(pred=nbPredict,true=test$activity)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print confusion matrix\n#confusionMatrix() will also ouput accuracy, sensitivity, and specificity!\nconfusionMatrix(nbPredict, test$activity)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8-(2) Decision Tree","metadata":{}},{"cell_type":"code","source":"if (!require(\"rpart\", quietly=TRUE)) {\n  install.packages(\"rpart\", repos=\"https://cloud.r-project.org/\",\n                   quiet=TRUE, type=\"binary\")\n  library(\"rpart\")\n}\nif (!require(\"rpart.plot\", quietly=TRUE)) {\n  install.packages(\"rpart.plot\", repos=\"https://cloud.r-project.org/\",\n                   quiet=TRUE, type=\"binary\")\n  library(\"rpart.plot\")\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We’re using RPART to build our Decision Tree. The rpart package uses the Recursive Partitioning And Regression Trees algorithm.","metadata":{}},{"cell_type":"code","source":"# build the tree with the rpart package\ntree <- rpart(activity~.,\n              data=train,\n              method = \"class\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use rpart.plot to vkisualize our decidion tree\nrpart.plot(tree, nn=TRUE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing\ntreePredict <- predict(object=tree,test[-1],type=\"class\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table(treePredict, test$activity)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#view the confusion matrix along with other stats on the model\nconfusionMatrix(treePredict, test$activity)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Model building through cross-validation","metadata":{}},{"cell_type":"markdown","source":"## !!Python below!!!","metadata":{}},{"cell_type":"markdown","source":"In the above section, the models were developed using the default values for many optional hyperparamters, which cannot be learned by the training algorithm.  For example, when building a decision tree model, one should specify how the tree should be deep, how many compounds should be allowed in a single leaf, what is the minimum number of compounds in a single leaf, etc.","metadata":{}},{"cell_type":"markdown","source":"The cells below demonstrate how to perform hyperparameter optimization through 10-fold cross-validation.  In this example, five values for each of three hyperparameters used in decision tree are considered (max_depth, min_samples_split, and min_samples_leaf), resulting in a total of 125 combination of the parameter values (=5 x 5 x 5).  For each combination, 10 models are generated (through 10-fold cross validation) and the average performance will be tracked.  The goal is to find the parameter value combination that results in the highest average performance score (e.g., 'roc_auc') from the 10-fold cross validation.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = [ 'roc_auc', 'balanced_accuracy' ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ncvs = 10\n\nmax_depth_range         = np.linspace( 3, 7, num=5, dtype='int32' )\nmin_samples_split_range = np.linspace( 3, 7, num=5, dtype='int32' )\nmin_samples_leaf_range  = np.linspace( 2, 6, num=5, dtype='int32' )\n\nparam_grid = dict( max_depth=max_depth_range,\n                   min_samples_split=min_samples_split_range,\n                   min_samples_leaf=min_samples_leaf_range )\n\nclf = GridSearchCV( DecisionTreeClassifier( random_state=0 ),\n                    param_grid=param_grid, cv=ncvs, scoring=scores, refit='roc_auc',\n                    return_train_score = True, iid=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit( X_train, y_train )\nprint(\"Best parameter set\", clf.best_params_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If necessary, it is possible to look into the performance data for each parameter value combination (stored in **clf.cv_results_**), as shown in the following cell.","metadata":{}},{"cell_type":"code","source":"means_1a = clf.cv_results_['mean_train_roc_auc']\nstds_1a  = clf.cv_results_['std_train_roc_auc']\n\nmeans_1b = clf.cv_results_['mean_test_roc_auc']\nstds_1b  = clf.cv_results_['std_test_roc_auc']\n\nmeans_2a = clf.cv_results_['mean_train_balanced_accuracy']\nstds_2a  = clf.cv_results_['std_train_balanced_accuracy']\n\nmeans_2b = clf.cv_results_['mean_test_balanced_accuracy']\nstds_2b  = clf.cv_results_['std_test_balanced_accuracy']\n\niterobjs = zip( means_1a, stds_1a, means_1b, stds_1b,\n                means_2a, stds_2a, means_2b, stds_2b, clf.cv_results_['params'] )\n\nfor m1a, s1a, m1b, s1b, m2a, s2a, m2b, s2b, params in iterobjs :\n\n    print( \"Grid %r : %0.4f %0.04f %0.4f %0.04f %0.4f %0.04f %0.4f %0.04f\"\n           % ( params, m1a, s1a, m1b, s1b, m2a, s2a, m2b, s2b))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment the following cell to look into additional performance data stored in cv_result_.","metadata":{}},{"cell_type":"code","source":"#print(clf.cv_results_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is important to understand that each model built through 10-fold cross-validation during hyperparameter optimization uses only 90% of the compounds in the training set and the remaining 10% is used for testing that model.  After all parameter value combinations are evaluated, the best parameter values are selected and used to rebuild a model from **all** compounds in the training set.  **GridSearchCV()** takes care of this last step automatically.  Therefore, there is no need to take an extra step to build a model using **cls.fit()** after hyperparameter optimization.","metadata":{}},{"cell_type":"code","source":"y_true, y_pred = y_train, clf.predict( X_train )    # Apply the model to predict the training compound's activity.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CMat = confusion_matrix( y_true, y_pred )    #-- generate confusion matrix\nprint(CMat)    # [[TN, FP], \n               #  [FN, TP]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc  = accuracy_score( y_true, y_pred )\n\nsens = CMat[ 1 ][ 1 ] / ( CMat[ 1 ][ 0 ] + CMat[ 1 ][ 1 ] )    # TP / (FN + TP)\nspec = CMat[ 0 ][ 0 ] / ( CMat[ 0 ][ 0 ] + CMat[ 0 ][ 1 ] )    # TN / (TN + FP )\nbacc = (sens + spec) / 2\n\ny_score = clf.predict_proba( X_train )[:, 1]\nauc = roc_auc_score( y_true, y_score )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"#-- Accuracy          = \", acc)\nprint(\"#-- Balanced Accuracy = \", bacc)\nprint(\"#-- Sensitivity       = \", sens)\nprint(\"#-- Specificity       = \", spec)\nprint(\"#-- AUC-ROC           = \", auc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare these performance data with those from section 8-(2) (for the training set).  When the default values were used, the DT model gave >0.99 for all performance measures, but the current models (developed using hyperparameter optimization) have much lower values, ranging from 0.73 to 0.83.  Again, however, what really matters is the performance against the test set, which contains the data not used for model training. ","metadata":{}},{"cell_type":"code","source":"y_true, y_pred = y_test, clf.predict(X_test)    #-- Apply the model to predict the test set compounds' activity.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CMat = confusion_matrix( y_true, y_pred )    #-- generate confusion matrix\nprint(CMat)    # [[TN, FP], \n               #  [FN, TP]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc  = accuracy_score( y_true, y_pred )\n\nsens = CMat[ 1 ][ 1 ] / ( CMat[ 1 ][ 0 ] + CMat[ 1 ][ 1 ] )\nspec = CMat[ 0 ][ 0 ] / ( CMat[ 0 ][ 0 ] + CMat[ 0 ][ 1 ] )\nbacc = (sens + spec) / 2\n\ny_score = clf.predict_proba( X_test )[:, 1]\nauc = roc_auc_score( y_true, y_score )\n\nprint(\"#-- Accuracy          = \", acc)\nprint(\"#-- Balanced Accuracy = \", bacc)\nprint(\"#-- Sensitivity       = \", sens)\nprint(\"#-- Specificity       = \", spec)\nprint(\"#-- AUC-ROC           = \", auc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can see that the model from hyperparameter optimization gives better performance data against the test set, compared to the model developed using the default parameter values.  Importantly, the model from hyperparameter optimization shows smaller differences in performance measures between the training and test sets, indicatiing that the issue of outffiting has been alleviated substantially.","metadata":{}},{"cell_type":"markdown","source":"# Exercises","metadata":{}},{"cell_type":"markdown","source":"In this assignment, we will build predictive models using the same aromatase data.","metadata":{}},{"cell_type":"markdown","source":"**step 1** Show the following information to make sure that the activity data in the **df_activity** data frame is still available.","metadata":{}},{"cell_type":"markdown","source":"- The first five lines of **df_activity**","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The counts of active/inactive compounds in **df_activity**","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 2** Show the following information to make sure the structure data is still available.","metadata":{}},{"cell_type":"markdown","source":"- The first five lines of **df_smiles**","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- the number of rows of **df_smiles**","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 3** Generate the (ECFP-equivalent) circular fingerprints from the SMILES strings.\n- Use RDKit to generate 1024-bit-long circular fingerprints.\n- Set the radius of the circular fingerprint to 2.\n- Store the fingerprints in a data_frame called **df_fps** (along with the CIDs).\n- Print the dimension of **df_fps**.\n- Show the first five lines of **df_fps**.","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 4** Merge the **df_activity** and **df_fps** data frames into a data frame called **df_data**\n- Join the two data frames using the CID column as keys.\n- Remove the rows that have any NULL values (i.e., compounds for which the fingerprints couldn't be generated).\n- Print the dimension of **df_data**.\n- Show the first five lines of **df_data**.","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 5** Prepare input and output data for model building\n- Load the fingerprint data into 2-D array (X) and the activity data into 1-D array (y).\n- Show the dimension of X and y.","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Remove zero-variance features from X (if any).","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Split the data set into training and test sets (90% vs 10%) (using random_state=3100).\n- Print the dimension of X and y for the training and test sets.","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Balance the training data set through downsampling.\n- Show the number of inactive/active compounds in the downsampled training set.","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 6** Building a Random Forest model using the balanced training data set.\n- First read the followng documents about random forest (https://scikit-learn.org/stable/modules/ensemble.html#forest and https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier). \n- Use 10-fold cross validation to select the best value for the \"n_estimators\" parameter that maximizes the **balanced accuracy**.  Test 40 values from 5 to 200 with an increment of 5 (e.g., 5, 10, 15, 20, ..., 190, 195, 200).\n- For parameters 'max_depth', 'min_samples_leaf', and 'min_samples_split', use the best values found in Section 9.\n- For other parameters, use the default values.\n- For each parameter value, print the mean balanced accuracies (for both training and test from cross validation). ","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 7** Apply the developed RF model to predict the activity of the **training** set compounds.\n\n- Report the confusion matrix.\n- Report the accuracy, balanced accurayc, sensitivity, specificity, and auc-roc.","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 8** Apply the developed RF model to predict the activity of the **test** set compounds.\n\n- Report the accuracy, balanced accurayc, sensitivity, specificity, and auc-roc.","metadata":{}},{"cell_type":"code","source":"# Write your code in this cell.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 9** Read a recent paper published in *Chem. Res. Toxicol.* (https://doi.org/10.1021/acs.chemrestox.7b00037) and answer the following questions (in no more than five sentences for each question).\n\n- What different approaches did the paper take to develop prediction models (compared to those used in this notebook)?\n- How different are the models reported in the paper from those constructed in this paper (in terms of the performance measures)? \n- What would you do to develop models with improved performance?","metadata":{}},{"cell_type":"code","source":"#Write your answers in this cell.","metadata":{},"execution_count":null,"outputs":[]}]}